{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tstatus\trepository\tauthors\tcitation\turl_slug\tpaper_url\tslides_url\tcategory\texcerpt\n",
      "6/15/19\t\"Glacier-Surface Velocity Derived Ice Volume and Retreat Assessment in the Dhauliganga Basin, Central Himalaya - A Remote Sensing and Modeling Based Approach\"\tPublished\tFrontiers in Earth Science\t\"Sattar, A., Goswami, A., Kulkarni, A. V., & Das, P.\"\t\"Sattar, A., Goswami, A., Kulkarni, A. V., & Das, P. (2019). Glacier-Surface Velocity Derived Ice Volume and Retreat Assessment in the Dhauliganga Basin, Central Himalaya - A Remote Sensing and Modeling Based Approach. Frontiers in Earth Science, 7, 105. https://doi.org/10.3389/feart.2019.00105\"\tglacier-surface-velocity\thttps://doi.org/10.3389/feart.2019.00105\t\tmanuscript\t\n",
      "5/15/22\tReservoir Assessment Tool 2.0: Stakeholder driven improvements to satellite remote sensing based reservoir monitoring\tPublished\tEnvironmental Modelling & Software\t\"Das, P., Hossain, F., Khan, S., Biswas, N. K., Lee, H., Piman, T., Meechaiya, C., Ghimire, U., & Hosen, K.\"\t\"Das, P., Hossain, F., Khan, S., Biswas, N. K., Lee, H., Piman, T., Meechaiya, C., Ghimire, U., & Hosen, K. (2022). Reservoir Assessment Tool 2.0: Stakeholder driven improvements to satellite remote sensing based reservoir monitoring. Environmental Modelling & Software, 157, 105533. https://doi.org/10.1016/j.envsoft.2022.105533\"\treservoir-assessment-tool-2\thttps://doi.org/10.1016/j.envsoft.2022.105533\t\tmanuscript\t\n",
      "12/15/22\tBuilding User-Readiness for Satellite Earth Observing Missions: The Case of the Surface Water and Ocean Topography (SWOT) Mission\tPublished\tAGU Advances\t\"Hossain, F., Das, P., Srinivasan, M., Tsontos, V., Oaida, C. M., Nickles, C., McNelis, J., Bonnema, M., et al.\"\t\"Hossain, F., Das, P., Srinivasan, M., Tsontos, V., Oaida, C. M., Nickles, C., McNelis, J., Bonnema, M., et al. (2022). Building User-Readiness for Satellite Earth Observing Missions: The Case of the Surface Water and Ocean Topography (SWOT) Mission. AGU Advances, 3(6). https://doi.org/10.1029/2022AV000680\"\tswot-mission-user-readiness\thttps://doi.org/10.1029/2022AV000680\t\tmanuscript\t\n",
      "3/15/23\tUnderstanding Volume Estimation Uncertainty of Lakes and Wetlands Using Satellites and Citizen Science\tPublished\tIEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\t\"Khan, S., Hossain, F., Pavelsky, T., Parkins, G. M., Lane, M. R., Gomez, A. M., Minocha, S., Das, P., et al.\"\t\"Khan, S., Hossain, F., Pavelsky, T., Parkins, G. M., Lane, M. R., Gomez, A. M., Minocha, S., Das, P., et al. (2023). Understanding Volume Estimation Uncertainty of Lakes and Wetlands Using Satellites and Citizen Science. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 16, 2386–2401. https://doi.org/10.1109/JSTARS.2023.3250354\"\tlakes-wetlands-volume-estimation\thttps://doi.org/10.1109/JSTARS.2023.3250354\t\tmanuscript\t\n",
      "12/15/23\tReservoir Assessment Tool Version 3.0: A Scalable and User-Friendly Software Platform to Mobilize the Global Water Management Community\tPublished\tGeoscientific Model Development Discussions\t\"Minocha, S., Hossain, F., Das, P., Suresh, S., Khan, S., Darkwah, G., Lee, H., Galelli, S., Andreadis, K., & Oddo, P.\"\t\"Minocha, S., Hossain, F., Das, P., Suresh, S., Khan, S., Darkwah, G., Lee, H., Galelli, S., Andreadis, K., & Oddo, P. (2023). Reservoir Assessment Tool Version 3.0: A Scalable and User-Friendly Software Platform to Mobilize the Global Water Management Community. Geoscientific Model Development Discussions, 2023, 1–23. https://doi.org/10.5194/gmd-2023-130\"\treservoir-assessment-tool-3\thttps://doi.org/10.5194/gmd-2023-130\t\tmanuscript\t\n",
      "1/15/24\t\"Satellite-based Tracking of Reservoir Operations for Flood Management during the 2018 Extreme Weather Event in Kerala, India\"\tPublished\tRemote Sensing of Environment\t\"Suresh, S., Hossain, F., Minocha, S., Das, P., Khan, S., Lee, H., Andreadis, K., & Oddo, P.\"\t\"Suresh, S., Hossain, F., Minocha, S., Das, P., Khan, S., Lee, H., Andreadis, K., & Oddo, P. (2024). Satellite-based tracking of reservoir operations for flood management during the 2018 extreme weather event in Kerala, India. Remote Sensing of Environment, 307, 114149. https://doi.org/10.1016/j.rse.2024.114149\"\tsatellite-reservoir-flood-management\thttps://doi.org/10.1016/j.rse.2024.114149\t\tmanuscript\t\n",
      "1/15/24\tResORR: A globally scalable and satellite data-driven algorithm for river flow regulation due to reservoir operations\tPublished\tEnvironmental Modelling & Software\t\"Das, P., Hossain, F., Minocha, S., Suresh, S., Darkwah, G. K., Lee, H., Andreadis, K., Laverde-Barajas, M., & Oddo, P.\"\t\"Das, P., Hossain, F., Minocha, S., Suresh, S., Darkwah, G. K., Lee, H., Andreadis, K., Laverde-Barajas, M., & Oddo, P. (2024). ResORR: A globally scalable and satellite data-driven algorithm for river flow regulation due to reservoir operations. Environmental Modelling & Software, 176, 106026. https://doi.org/10.1016/j.envsoft.2024.106026\"\tresorr-global-river-flow\thttps://doi.org/10.1016/j.envsoft.2024.106026\t\tmanuscript\t\n",
      "1/15/24\tAssessing Snow Cover Patterns in the Indus-Ganga-Brahmaputra River Basins of the Hindu Kush Himalayas using Snow Persistence and Snow Line as Metrics\tPublished\tEnvironmental Challenges\t\"Dixit, A., Goswami, A., Jain, S., & Das, P. \"\t\"Dixit, A., Goswami, A., Jain, S., & Das, P. (2024). Assessing snow cover patterns in the Indus-Ganga-Brahmaputra River Basins of the Hindu Kush Himalayas using snow persistence and snow line as metrics. Environmental Challenges, 14, 100834. https://doi.org/10.1016/j.envc.2023.100834\"\tsnow-cover-hindu-kush-himalayas\thttps://doi.org/10.1016/j.envc.2023.100834\t\tmanuscript\t\n",
      "3/15/24\tReservoir Assessment Tool (RAT): A Python Package for Monitoring the Dynamic State of Reservoirs and Analyzing Dam Operations\tIn Review\tDigital Water\t\"S. Minocha, Das, P., and F. Hossain.\"\t\"S. Minocha, Das, P., and F. Hossain. (2024) Reservoir assessment tool (rat): A python package for monitoring the dynamic state of reservoirs and analyzing dam operations. Digital Water (in review)\"\treservoir-assessment-tool-package\t\t\tmanuscript\t\n",
      "4/15/24\t\"Remote Sensing of Snow Cover Dynamics and Climate Implications in the Indus, Ganga, and Brahmaputra River Basins\"\tPublished\tClimate Dynamics\t\"Dixit, A., Goswami, A., Jain, S. K., & Das, P.\"\t\"Dixit, A., Goswami, A., Jain, S. K., & Das, P. (2024). Remote sensing of snow cover dynamics and climate implications in the Indus, Ganga, and Brahmaputra river basins. Climate Dynamics, 62(8), 7309-7327. https://doi.org/10.1007/s00382-024-07280-5\"\tsnow-cover-river-basins\thttps://doi.org/10.1007/s00382-024-07280-5\t\tmanuscript\t\n",
      "11/15/24\tForecast informed reservoir operations within a satellite based framework for mountainous and high precipitation regions: The case of the 2018 kerala floods\tPublished\tJournal of Hydrologic Engineering\t\"Das, P., S. Suresh, F. Hossain, V. Balakrishnan, J. P J, H. Lee, M. Laverde, K. Hosen, C. Meechaiya, and P. Towashiraporn. \"\t\"Das, P., S. Suresh, F. Hossain, V. Balakrishnan, J. P J, H. Lee, M. Laverde, K. Hosen, C. Meechaiya, and P. Towashiraporn. (2024). Forecast informed reservoir operations within a satellite based framework for mountainous and high precipitation regions: The case of the 2018 kerala floods. ASCE Journal of Hydrologic Engineering (in revision).\"\tforecasting-informed-reservoir-operations\t\t\tmanuscript\t\n",
      "12/28/24\tMulti-satellite Tracking of Surface Water Storage Change in the Era of Surface Water and Ocean Topography (SWOT) Satellite Mission\tSubmitted\t\"Earth and Space Science, Science from the Surface Water and Ocean Topography Mission\"\t\"Das, P., and F. Hossain\"\t\"Das, P., and F. Hossain. (2024). Multi-satellite Tracking of Surface Water Storage Change in the Era of Surface Water and Ocean Topography (SWOT) Satellite Mission. Earth and Space Science, Science from the Surface Water and Ocean Topography Mission (submitted).\"\tswot-storage\t\t\tmanuscript\t\n",
      "10/3/24\tReconstruction of the Hydro Thermal Behavior of Regulated River Networks of the Columbia River Basin Using Satellite Remote Sensing and Data Driven Techniques\tPublished\tEarth's Future\t\"Darkwah, G. K., Hossain, F., Tchervenski, V., Holtgrieve, G., Graves, D., Seaton, C., Minocha, S., Das, P., Khan, S., & Suresh, S.\"\t\"Darkwah, G. K., Hossain, F., Tchervenski, V., Holtgrieve, G., Graves, D., Seaton, C., Minocha, S., Das, P., Khan, S., & Suresh, S. (2024). Reconstruction of the Hydro Thermal Behavior of Regulated River Networks of the Columbia River Basin Using Satellite Remote Sensing and Data_Driven Techniques. Earth's Future, 12(10), e2024EF004815. https://doi.org/10.1029/2024EF004815\"\tthorr\thttps://doi.org/10.1029/2024EF004815\t\tmanuscript\t\n",
      "7/18/22\t\"Satellites over the amazon capture the choking of the 'house of god' by the belo monte dam - they can help find solutions, too\"\tPublished\tThe Conversation\t\"Das, P., F. Hossain, H. B. Helgason, and S. Khan\"\t\"Das, P., F. Hossain, H. B. Helgason, and S. Khan. (2022). Satellites over the amazon capture the choking of the 'house of god' by the belo monte dam - they can help find solutions, too. \"\tconversation-house-of-god\thttps://theconversation.com/satellites-over-the-amazon-capture-the-choking-of-the-house-of-god-by-the-belo-monte-dam-they-can-help-find-solutions-too-182012\t\tmagazine\t\n",
      "9/15/24\tSatellite Remote Sensing for Water Management\tIn Press\tCambridge University Publishers.\tFaisal Hossain\t\"Hossain, F. (2024). Satellite Remote Sensing for Water Management. Cambridge University Press.\"\tsatellite-remote-sensing-book\t\t\tbook\t"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/h464qnw52wq0lwvhs1s03dy40000gp/T/ipykernel_23621/18735958.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0, parse_dates=['pub_date'])\n"
     ]
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0, parse_dates=['pub_date'])\n",
    "publications\n",
    "\n",
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "# ## Escape special characters\n",
    "# YAML is very picky about how it takes a valid string, so we are replacing single and double \n",
    "# quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable \n",
    "# in raw format, but they are parsed and rendered nicely.\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "\n",
    "## Creating the markdown files\n",
    "# This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, \n",
    "# then starts to concatentate a big string (```md```) that contains the markdown for each type.\n",
    "# It does the YAML metadata first, then does the description for the individual page.\n",
    "\n",
    "\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date.year) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date.year) + \"-\" + item.url_slug\n",
    "    year = item.pub_date.year\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\nstatus: \"\"\"  + item.status\n",
    "\n",
    "    md += \"\"\"\\ncategory: \"\"\" + item.category\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date.date()) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.repository) + \"'\"\n",
    "    \n",
    "    if len(str(item.slides_url)) > 5:\n",
    "        md += \"\\nslidesurl: '\" + item.slides_url + \"'\"\n",
    "\n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "\n",
    "    # if len(str(item.slides_url)) > 5:\n",
    "    #     md += \"\\n[Download slides here](\" + item.slides_url + \")\\n\" \n",
    "\n",
    "    # if len(str(item.paper_url)) > 5:\n",
    "    #     md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-glacier-surface-velocity.md\n",
      "2022-conversation-house-of-god.md\n",
      "2022-reservoir-assessment-tool-2.md\n",
      "2022-swot-mission-user-readiness.md\n",
      "2023-lakes-wetlands-volume-estimation.md\n",
      "2023-reservoir-assessment-tool-3.md\n",
      "2024-forecasting-informed-reservoir-operations.md\n",
      "2024-reservoir-assessment-tool-package.md\n",
      "2024-resorr-global-river-flow.md\n",
      "2024-satellite-reservoir-flood-management.md\n",
      "2024-snow-cover-hindu-kush-himalayas.md\n",
      "2024-snow-cover-river-basins.md\n",
      "2024-swot-storage.md\n",
      "2024-thorr.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Paper Title Number 1\"\n",
      "collection: publications\n",
      "permalink: /publication/2009-10-01-paper-title-number-1\n",
      "excerpt: 'This paper is about the number 1. The number 2 is left for future work.'\n",
      "date: 2009-10-01\n",
      "venue: 'Journal 1'\n",
      "slidesurl: 'http://academicpages.github.io/files/slides1.pdf'\n",
      "paperurl: 'http://academicpages.github.io/files/paper1.pdf'\n",
      "citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'\n",
      "---\n",
      "This paper is about the number 1. The number 2 is left for future work.\n",
      "\n",
      "[Download slides here](http://academicpages.github.io/files/slides1.pdf)\n",
      "\n",
      "[Download paper here](http://academicpages.github.io/files/paper1.pdf)\n",
      "\n",
      "Recommended citation: Your Name, You. (2009). \"Paper Title Number 1.\" <i>Journal 1</i>. 1(1)."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2009-10-01-paper-title-number-1.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Do the opposite: generate a TSV from a list of markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing YAML in file /Users/pdas47/cv/_publications/2024-damnet.md: while parsing a block mapping\n",
      "  in \"<unicode string>\", line 2, column 1:\n",
      "    title: \"Damnet: A visualization  ... \n",
      "    ^\n",
      "expected <block end>, but found '<scalar>'\n",
      "  in \"<unicode string>\", line 11, column 112:\n",
      "     ... s as transit hubs for the world's water. Journal of Visualizatio ... \n",
      "                                         ^\n",
      "Error parsing YAML in file /Users/pdas47/cv/_publications/2024-thorr.md: while parsing a block mapping\n",
      "  in \"<unicode string>\", line 2, column 1:\n",
      "    title: \"Reconstruction of the Hy ... \n",
      "    ^\n",
      "expected <block end>, but found '<scalar>'\n",
      "  in \"<unicode string>\", line 8, column 15:\n",
      "    venue: 'Earth's Future'\n",
      "                  ^\n",
      "TSV file created: /Users/pdas47/cv/markdown_generator/publications-auto.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the publication files\n",
    "publications_dir = '/Users/pdas47/cv/_publications'\n",
    "\n",
    "# Define the output TSV file\n",
    "output_tsv = '/Users/pdas47/cv/markdown_generator/publications-auto.tsv'\n",
    "\n",
    "# Define the header for the TSV file\n",
    "header = ['pub_date', 'title', 'venue', 'excerpt', 'citation', 'url_slug', 'paper_url', 'slides_url']\n",
    "\n",
    "# Initialize a list to store the publication data\n",
    "publications_data = []\n",
    "\n",
    "# Function to extract metadata from the markdown file\n",
    "def extract_metadata(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "        try:\n",
    "            front_matter = content.split('---')[1]\n",
    "            metadata = yaml.safe_load(front_matter)\n",
    "            return metadata\n",
    "        except yaml.YAMLError as e:\n",
    "            print(f\"Error parsing YAML in file {filepath}: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Iterate over the files in the publications directory\n",
    "for filename in os.listdir(publications_dir):\n",
    "    if filename.endswith('.md'):\n",
    "        filepath = os.path.join(publications_dir, filename)\n",
    "        metadata = extract_metadata(filepath)\n",
    "        pub_date = metadata.get('date', '')\n",
    "        title = metadata.get('title', '')\n",
    "        venue = metadata.get('venue', '')\n",
    "        excerpt = metadata.get('excerpt', '')\n",
    "        citation = metadata.get('citation', '')\n",
    "        url_slug = metadata.get('permalink', '').split('/')[-1]\n",
    "        paper_url = metadata.get('paperurl', '')\n",
    "        slides_url = metadata.get('slidesurl', '')\n",
    "        publications_data.append([pub_date, title, venue, excerpt, citation, url_slug, paper_url, slides_url])\n",
    "\n",
    "# Create a DataFrame and write to TSV\n",
    "df = pd.DataFrame(publications_data, columns=header)\n",
    "df.to_csv(output_tsv, sep='\\t', index=False)\n",
    "\n",
    "print(f'TSV file created: {output_tsv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
